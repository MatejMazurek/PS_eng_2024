{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Exercise 9. Interval estimates(one selection) ## Michal B\u00e9re\u0161, Martina Litschmannov\u00e1, Veronika Kub\u00ed\u010dkov\u00e1\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Demonstration at the beginning - what is interval estimation?\n \n", "Consider a random variable from the normal distribution with a mean value of $\\mu$ and a standard deviation of $\\sigma$. We will work with selections from this random variable and help them try to estimate the mean value of the distribution(here we know its true value, but in practice its value is unknown).\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 30        # selection size\n", "mu = 100      # mean value\n", "sigma = 10    # direction. deviation\n", "\n", "# simulation of random selection from a given random variable\n", "vyber = rnorm(n = n, mean = mu, sd = sigma)\n", "\n", "X = mean(vyber) # sampling average as a point estimate\n", "S = sd(vyber)   # selection direction. departure\n", "X\n", "S"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For clarity, we can visualize the selection.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["options(repr.plot.width = 12) # width of graphs in Jupyter\n", "par(mfrow = c(1, 2))          # graph matrix 1x2\n", "\n", "hist(vyber)\n", "boxplot(vyber)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### The construction of the interval estimation itself using a selection characteristic\n \n", "We will use this selection characteristic:(we assume that we do not know any real parameters of the distribution, only that it is normal)<br>$Y=\\frac{\\bar X - \\mu}{S}\\sqrt{n} \\sim t_{n-1}$<br>Since we know the distribution of Y, we are able to compute $a$ a $b$ in the following expression:<br>$P(a<Y<b)\\geq 1 - \\alpha$<br>\n \n", "- $\\alpha$ is called the significance level(the probability that the searched value is outside our range)\n \n", "- $1-\\alpha$ is called the interval estimation reliability\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$a$ a $b$ so that they are symmetric in probability, ie:\n \n", "- $P(Y<a)\\leq \\alpha / 2 \\rightarrow a=t_{\\alpha / 2;n-1}$\n \n", "- $P(b<Y)\\leq \\alpha / 2 \\rightarrow P(Y\\leq b)\\geq 1 - \\alpha / 2 \\rightarrow b=t_{1-\\alpha / 2;n-1}$\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# maximum probability with which we allow\n", "# real st. hours lay outside the constructed interval\n", "alpha = 0.05 \n", "\n", "# relevant quantiles of the student's distribution\n", "t_low = qt(alpha/2, df = n-1)\n", "t_high = qt(1 - alpha/2, df = n-1)\n", "\n", "t_low\n", "t_high"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next we just add to the expression and modify:<br>$P(t_{\\alpha / 2;n-1}<\\frac{\\bar X - \\mu}{S}\\sqrt{n}<t_{1-\\alpha / 2;n-1})\\geq 1 - \\alpha$<br>$P(\\bar X - t_{1-\\alpha / 2;n-1}\\frac{S}{\\sqrt{n}}<\\mu<\\bar X - t_{\\alpha / 2;n-1}\\frac{S}{\\sqrt{n}})\\geq 1 - \\alpha$<br>\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["I_dolni = X - t_high*S/sqrt(n)\n", "I_horni = X - t_low*S/sqrt(n)\n", "paste(\"P(\", I_dolni, \" < \u00b5 < \", I_horni, \") \u2265 \", 1-alpha)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This particular estimate can also be obtained using the Rkov function t.test:\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t.test(vyber, alternative = 'two.sided', conf.level = 1-alpha)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Testing interval estimation on multiple selections\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["count_pokusu = 10000 # number of selections\n", "\n", "n = 30             # selection size\n", "mu = 100           # mean value\n", "sigma = 10         # guided. deviation.\n", "\n", "alpha = 0.05        # significance level\n", "\n", "# relevant quantiles of the student's distribution\n", "t_low = qt(alpha/2, df = n-1)\n", "t_high = qt(1 - alpha/2, df = n-1)\n", "\n", "# plot of the actual mean value\n", "plot(c(1, count_pokusu), c(mu, mu), type = 'l', ylim = c(90,110))\n", "\n", "count_neuspesnych = 0\n", "# cycle through individual selections\n", "for(i in 1:count_pokusu){\n", "    vyber = rnorm(n = n, mean = mu, sd = sigma)\n", "    X = mean(vyber)\n", "    S = sd(vyber)\n", "    I_dolni = X - t_high*S/sqrt(n)\n", "    I_horni = X - t_low*S/sqrt(n)\n", "    \n", "    # select the plot color, depending on whether the IO contains the middle hour.\n", "    if( I_dolni<mu & mu<I_horni){\n", "        barva = \"blue\"      \n", "    }else{\n", "        barva = \"red\"\n", "        count_neuspesnych = count_neuspesnych + 1\n", "    }\n", "    # draw the IC as a vertical line\n", "    lines(c(i, i), c(I_dolni, I_horni), col=barva)  \n", "}\n", "paste('alpha = ', alpha, ', relativn\u00ed \u010detnost n\u011b\u00fasp\u011b\u0161n\u00fdch IO = ', \n", "      count_neuspesnych/count_pokusu)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# I will return the width to the standard size\n", "options(repr.plot.width = 8) # width of graphs in Jupyter\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Types of interval estimates\n \n", "Examples of estimating the mean value of data from a normal distribution.)\n \n", "## Bottom/Left IC\n \n", "- $P(M_D^* < \\mu) = 1-\\alpha$\n \n", "- in Rku **alternative=\"greater\"**\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rnorm(n = 30, mean = 100, sd = 10)\n", "alpha = 0.05\n", "t.test(vyber, alternative = 'greater', conf.level = 1-alpha)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Top/Right IO\n \n", "- $P(\\mu < M_H^*) = 1-\\alpha$\n \n", "- in Rku **alternative=\"less\"**\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rnorm(n = 30, mean = 100, sd = 10)\n", "alpha = 0.05\n", "t.test(vyber, alternative = 'less', conf.level = 1-alpha)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Double-sided IC\n \n", "- $P(M_D < \\mu < M_H) = 1-\\alpha$\n \n", "- in Rku **alternative=\"two.sided\"**\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rnorm(n = 30, mean = 100, sd = 10)\n", "alpha = 0.05\n", "t.test(vyber, alternative = 'two.sided', conf.level = 1-alpha)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Overview of selection parameters and their point/interval estimates\n \n", "We usually have more IO constructions(functions in Rk that will do this for us), but each construction has different data requirements and produces different \"quality\"(in terms of IO size) estimates. We will always select the \"best quality\" IC that **has met** the prerequisites for use.<br>The order of the various ICs below will always be from \"best\" to most robust.\n \n", "## Position measures of one selection\n \n", "By position measures we mean the data that determines the position of the data, no matter how scattered. For data from the normal distribution we can estimate the mean value, for others the median.\n \n", "#### a) student's IC t-test\n \n", "- we estimate the mean value - the point estimate is the sample average\n \n", "- the data must come from a normal distribution\n \n", "- exploratory: skewness and sharpness lie in(-2,2)\n \n", "- Explosive: The QQ graph has points approximately on the line\n \n", "- exact: using a statistical test, eg Shapiro-Wilk test(shapiro.test(data))\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rnorm(n = 30, mean = 100, sd = 10)\n", "alpha = 0.05"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exploratory normality test\n", "# library(moments) - we can avoid this by calling moments ::\n", "# it's safer - we're sure we're calling a feature from this package\n", "moments::skewness(vyber)\n", "moments::kurtosis(vyber) - 3\n", "qqnorm(vyber)\n", "qqline(vyber)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exact data normality test\n", "shapiro.test(vyber)$p.value\n", "# the resulting p-value must be greater than hl. challenge(eg 0.05)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point estimate\n", "mean(vyber)\n", "# IO\n", "t.test(vyber, alternative = 'two.sided', conf.level = 1-alpha)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### b) Wilcoxn IC test\n \n", "- we estimate the median - the point estimate is the sample median\n \n", "- the data must come from a symmetric distribution\n \n", "- exploratory: the slope lies in(-2,2)\n \n", "- exploratory: the histogram looks approximately symmetrical\n \n", "- exactly: using a statistical test, eg \"lawstat\" package, \"symmetry.test(data, boot=FALSE)\" function\n \n", "- function in Rk requires additional parameter(conf.int=TRUE)\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = runif(n = 30, min = 80, max = 120)\n", "alpha = 0.05"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exploratory\n", "moments::skewness(vyber)\n", "hist(vyber, breaks = 5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exact: symmetry test\n", "# install.packages(\"lawstat\")\n", "library(lawstat)\n", "symmetry.test(vyber,boot=FALSE)$p.value\n", "# the resulting p-value must be greater than hl. challenge(eg 0.05)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point estimate\n", "quantile(vyber, probs = 0.5)\n", "median(vyber)\n", "# IO\n", "wilcox.test(vyber, alternative = 'two.sided', conf.level = 1-alpha, \n", "            conf.int = TRUE)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### c) sign test IO test\n \n", "- we estimate the median - the point estimate is the sample median\n \n", "- larger range selection(>10)\n \n", "- function in Rk requires additional parameter(conf.int=TRUE)\n \n", "- requires \"BSDA\" library\n \n", "- as the most robust test, it can also be used for discontinuous data - eg order in a list\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rexp(n = 30, rate = 1/100)\n", "alpha = 0.05"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# true median\n", "qexp(p = 0.5, rate = 1/100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point estimate\n", "# quantile(select, probs=0.5)\n", "median(vyber)\n", "# IO\n", "# install.packages(\"BSDA\")\n", "library(BSDA)\n", "SIGN.test(vyber, alternative = 'two.sided', conf.level = 1-alpha, \n", "          conf.int = TRUE)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Measures of variability of one selection\n \n", "By measures of variability we mean the data determining the dispersion/variability of the data, regardless of the total values. For data from the normal distribution, we can estimate the standard deviation.\n \n", "#### IO standard deviations\n \n", "- we estimate the standard deviation - the point estimate is the sample standard deviation\n \n", "- the data must come from a normal distribution\n \n", "- exploratory: skewness and sharpness lie in(-2,2)\n \n", "- exploratory: The QQ graph has points approximately on the line\n \n", "- exactly: using a statistical test, eg Shapiro-Wilk test(shapiro.test(data))\n \n", "- requires \"EnvStats\" package\n \n", "- function in Rku, gives the calculation of variance - the square root of the result is necessary\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vyber = rnorm(n = 30, mean = 100, sd = 10)\n", "alpha = 0.05"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exploratory normality test\n", "moments::skewness(vyber)\n", "moments::kurtosis(vyber) - 3\n", "qqnorm(vyber)\n", "qqline(vyber)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exact data normality test\n", "shapiro.test(vyber)$p.value\n", "# the resulting p-value must be greater than hl. challenge(eg 0.05)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point estimate\n", "sd(vyber)\n", "# IO\n", "# install.packages(\"EnvStats\")\n", "library(EnvStats)\n", "sqrt(varTest(vyber, alternative = 'two.sided', conf.level = 1-alpha)$conf.int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's add a manual calculation:\n \n", "- based on statistics: $\\frac{S^2}{\\sigma^2}(n-1) \\sim \\chi^2_{n-1}$\n \n", "- Upper limit:\n \n", "- $P(\\frac{S^2}{\\sigma^2}(n-1) < \\chi^2_{\\alpha /2, n-1}) = \\alpha /2$\n \n", "- $P(\\frac{S^2}{\\chi^2_{\\alpha /2, n-1}}(n-1) < \\sigma^2 ) = \\alpha /2$\n \n", "- Lower limit:\n \n", "- $P(\\frac{S^2}{\\sigma^2}(n-1) > \\chi^2_{1-\\alpha /2, n-1}) = \\alpha /2$\n \n", "- $P(\\frac{S^2}{\\chi^2_{1-\\alpha /2, n-1}}(n-1) > \\sigma^2 ) = \\alpha /2$\n \n", "- Together: $P(\\frac{S^2}{\\chi^2_{1-\\alpha /2, n-1}}(n-1) < \\sigma^2 <\\frac{S^2}{\\chi^2_{\\alpha /2, n-1}}(n-1)) = 1 - \\alpha$\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# manual calculation\n", "alpha = 0.05\n", "n = 30\n", "S = sd(vyber)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hor_q = qchisq(1 - alpha/2, n-1)\n", "dol_q = qchisq(alpha/2, n-1)\n", "hor_q\n", "dol_q"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sqrt(S^2*(n-1)/dol_q)\n", "sqrt(S^2*(n-1)/hor_q)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Probability of occurrence with one selection\n \n", "#### IO probability\n \n", "- we estimate the probability - the point estimate is the relative frequency\n \n", "- we need enough data: $n>\\frac{9}{p(1-p)}$\n \n", "- Clopper - Pearson estimate(binom.test)\n \n", "- does not take data as a parameter, but the number of successes and the number of observations\n \n", "- Wald's - from selection characteristics\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pi = 0.3\n", "n = 60\n", "alpha = 0.05\n", "vyber = runif(n = n, min = 0, max = 1) < pi"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# verification of assumptions\n", "p = mean(vyber)\n", "p\n", "9/(p*(1-p))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point estimate\n", "p\n", "# Clopper - Pearson interval estimation\n", "celk_count = length(vyber)\n", "count_poz = sum(vyber)\n", "binom.test(x = count_poz, n = celk_count, alternative = 'two.sided', \n", "           conf.level = 1 - alpha)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Wald's interval estimation\n", "dol_q = qnorm(alpha/2)\n", "hor_q = qnorm(1-alpha/2)\n", "\n", "p - hor_q*sqrt(p*(1-p)/n)   # lower IO limit\n", "p - dol_q*sqrt(p*(1-p)/n)       # upper IO limit\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculation of the 11 most frequently used confidence intervals param. bin. distribution\n", "# using binom package\n", "# install.packages(\"binom\")\n", "library(binom)\n", "binom.confint(n = celk_count, x = count_poz)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Examples\n \n", "## Example 1.\n \n", "During control tests of 16 light bulbs, an estimate of the mean value of $\\bar x$=3,000 hours and the standard deviation s=20 hours of their service life were determined. Assuming that the lamp life has a normal distribution, determine a 90% interval estimate for the \u00b5 and \u03c3 parameters\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We estimate the mean value and standard deviation of the lamp life\n", "# Part of the input is information about data normality\n", "\n", "n = 16         # file range\n", "x.bar = 3000   # hours.... average(point estimate of mean value)\n", "s = 20         # hours.... sample standard deviation(point estimate of standard deviation)\n", "alpha = 0.1    # significance level(reliability 1-alpha=0.9)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Bilateral interval estimate of the mean\n", "dol_q = qt(alpha/2,n-1)\n", "hor_q = qt(1 - alpha/2,n-1)\n", "\n", "x.bar - hor_q*s/sqrt(n)   # lower limit of IO\n", "x.bar - dol_q*s/sqrt(n)   # upper limit of IO\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Bilateral interval estimate of the standard deviation\n", "dol_q = qchisq(alpha/2,n-1)\n", "hor_q =  qchisq(1 - alpha/2,n-1)\n", "\n", "sqrt((n-1)*s^2/hor_q)      # lower IO limit\n", "sqrt((n-1)*s^2/dol_q)      # upper limit of IO\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 2.\n \n", "The depth of the sea is measured with an instrument whose systematic error is zero and the random errors have a normal distribution with a standard deviation of 20 m.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We determine the estimate of the required selection range(number of required measurements)\n", "\n", "# We assume data normality, with known variance(according to assignment)\n", "\n", "sigma = 20   # meters.... known standard deviation\n", "alpha = 0.05 # significance level(reliability 1-alpha=0.95)\n", "delta = 10   # meters... permissible measurement error\n", "\n", "# Estimate selection range\n", "# Y=delta/sigma * sqrt(n)~N(0,1), delta=X-mu\n", "# P(Y>Z_(1-alpha/2))=alpha/2\n", "\n", "(qnorm(1 - alpha/2)*sigma/delta)^2 "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 3.\n \n", "The task is to determine the average serum cholesterol level in a certain population of men. In a random sample(derived from the normal distribution) of 25 men, the sample mean is 6.3 mmol/l and the sample standard deviation is 1.3 mmol/l.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We estimate mean serum cholesterol levels\n", "# We assume data normality(according to assignment)\n", "\n", "n = 25        # file range\n", "x.bar = 6.3   # mmol/l.... average(point estimate of mean value)\n", "s = 1.3       # mmol/l.... selection direction. deviation(point estimate of deviation)\n", "alpha = 0.05  # significance level(reliability 1-alpha=0.95)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Bilateral interval estimate of the mean\n", "dol_q = qt(alpha/2, n-1)\n", "hor_q = qt(1 -alpha/2, n-1)\n", "\n", "x.bar - hor_q*s/sqrt(n)   # lower IO limit\n", "x.bar - dol_q*s/sqrt(n)   # upper limit of IC\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 4.\n \n", "Suppose that in a random selection of 200 young men, 120 of them have higher than recommended serum cholesterol levels. Determine a 95% confidence interval for the percentage of young men with higher cholesterol levels in the population.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We estimate the proportion of men with higher cholesterol levels in the entire population,\n", "# ie the probability that a randomly selected man will have a higher cholesterol level\n", "\n", "n = 200  # file range\n", "x = 120  # number of \"successes\"\n", "p = x/n  # relative frequency(probability point estimate)\n", "p\n", "alpha = 0.05 # significance level(reliability 1-alpha=0.95)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of assumptions\n", "9/(p*(1-p))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Bilateral Clopper - Pearson(exact) int. Estimate param. binom. distribution\n", "binom.test(x,n,alternative=\"two.sided\",conf.level=0.95)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Wald's(asymptotic) estimate(z-statistic) - approx. normal distribution according to CLV\n", "dol_q = qnorm(alpha/2)\n", "hor_q = qnorm(1-alpha/2)\n", "\n", "p - hor_q*sqrt(p*(1-p)/n)   # lower IO limit\n", "p - dol_q*sqrt(p*(1-p)/n)       # upper limit of IC\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 5.\n \n", "In a research study, we are working with a random selection of 70 women from the Czech population. Hemoglobin was measured in each of the women with an accuracy of 0.1 g/100 ml. The measured values are listed in the Hemoglobin.xls file. Find 95% interval estimates of standard deviation and mean hemoglobin in the population of Czech women.(Check the normality based on the exploration graphs.)\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # We estimate the mean and standard deviation of hemoglobin in serum\n", "\n", "# # Read data from xlsx file(using readxl package)\n", "library(readxl)\n", "hem = read_excel(\"data/intervalove_odhady.xlsx\",\n", "                  sheet = \"Hemoglobin\")\n", "colnames(hem) = \"hodnoty\"\n", "head(hem)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Exploratory analysis\n", "boxplot(hem$hodnoty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Data does not contain remote observations.\n", "summary(hem$hodnoty)\n", "sd(hem$hodnoty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of normality - exploratory\n", "qqnorm(hem$hodnoty)\n", "qqline(hem$hodnoty)\n", "\n", "moments::skewness(hem$hodnoty)\n", "moments::kurtosis(hem$hodnoty) - 3\n", "# Both skew and sharpness meet the standards. distribution.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normality verification: exact - normality test.\n", "# If we know hypothesis testing, we verify the Shapirs. Wilk's test.\n", "shapiro.test(hem$hodnoty)$p.value\n", "# In hl. significance 0.05\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 95% bilateral interval estimate of the mean\n", "mean(hem$hodnoty)\n", "t.test(hem$hodnoty, altarnative=\"two.sided\", conf.level=0.95)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # 95% two-way interval standard deviation estimate\n", "library(EnvStats)\n", "sd(hem$hodnoty)\n", "\n", "sqrt(varTest(hem$hodnoty, alternative = \"two.sided\", conf.level = 0.95)$conf.int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 6.\n \n", "What must be the number of observations if we want to determine the average hemoglobin value in newborns with an error of at most 1.0 $g/l$ with a probability of 0.95. Population variance is estimated at $g^2/l^2$.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We determine the estimated required range(number of newborns we have to test)\n", "\n", "# We assume data normality, without this assumption the example is unsolvable\n", "\n", "sigma = sqrt(46)  # g/l.... known standard deviation\n", "alpha = 0.05      # significance level(reliability 1-alpha=0.95)\n", "delta = 1         # g/l... permissible measurement error\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Estimate the range of the selection\n", "# Y=delta/sigma * sqrt(n)~N(0,1), delta=X-mu\n", "# P(Y>Z_(1-alpha/2))=alpha/2\n", "\n", "(qnorm(1 - alpha/2)*sigma/delta)^2 "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 7.\n \n", "In the data file pr7.xlsx you will find the measurement of noise caused by the computer fan [dB]. Calculate the 95% interval estimate of the average noise and the 95% interval estimate of the noise variability.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["library(readxl)\n", "# read data\n", "data = read_excel(\"data/pr7.xlsx\")\n", "head(data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(data$dB)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# visualization\n", "pom = boxplot(data$dB)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# removal of OP\n", "data_op = data\n", "data_op$dB[data_op$dB %in% pom$out] = NA\n", "data_op = na.omit(data_op)\n", "boxplot(data_op$dB)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# data normality test exploratory\n", "moments::skewness(data_op$dB)\n", "moments::kurtosis(data_op$dB) - 3\n", "\n", "qqnorm(data_op$dB)\n", "qqline(data_op$dB)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normality test exactly\n", "shapiro.test(data_op$dB)$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point and interval estimation of the mean\n", "mean(data_op$dB)\n", "\n", "t.test(data_op$dB, alternative = \"two.sided\", conf.level = 0.95)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# point and interval estimation of the standard deviation\n", "sd(data_op$dB)\n", "\n", "sqrt(varTest(data_op$dB,alternative = \"two.sided\", conf.level = 0.95)$conf.int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 8.\n \n", "In the data file pr8.xlsx you will find the measurement of the time to failure of the electrical component [h]. Calculate the 99% interval estimate of the average life of a given component type.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["library(readxl)\n", "# read data\n", "data = read_excel(\"data/pr8.xlsx\")\n", "head(data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# visualization and verification of OP\n", "boxplot(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hist(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# data normality test exploratory\n", "moments::skewness(data$cas_h)\n", "moments::kurtosis(data$cas_h) - 3\n", "\n", "qqnorm(data$cas_h)\n", "qqline(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normality test exactly\n", "shapiro.test(data$cas_h)$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# symmetry test exploratory\n", "moments::skewness(data$cas_h)\n", "hist(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exact: symmetry test\n", "# install.packages(\"lawstat\")\n", "library(lawstat)\n", "symmetry.test(data$cas_h,boot=FALSE)$p.value\n", "# the resulting p-value must be greater than hl. challenge(eg 0.05)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# median point and interval estimation\n", "median(data$cas_h)\n", "# IO\n", "# install.packages(\"BSDA\")\n", "alpha = 0.01\n", "library(BSDA)\n", "SIGN.test(data$cas_h, alternative = 'two.sided', conf.level = 1-alpha, \n", "          conf.int = TRUE)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sd(data$cas_h)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.0.4"}}, "nbformat": 4, "nbformat_minor": 4}