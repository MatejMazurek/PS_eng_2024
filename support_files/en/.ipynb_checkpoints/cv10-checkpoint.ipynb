{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Exercise 10. Introduction to hypothesis testing, one-sample tests ## Michal B\u00e9re\u0161, Martina Litschmannov\u00e1\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# From interval estimates to hypothesis tests\n \n", "## What is a statistical hypothesis test?\n \n", "Consider the following: - random variable X(for example, height of men) - selection from a random variable(measuring the height of 30 men) - alternative hypotheses For example:<br>$H_0$: $H_A$<br>$H_0$: $\\mu_X = 175$<br>Since this is a statistical decision, it will always be tied to some level of significance $H_A$. We can always reach only 2 different decisions: - I reject $H_0$ in favor of $H_0$ - that is, I say that $H_0$ does not apply - this decision is with the maximum error $H_A$(level of significance, type I error ) - this means that we are able to influence the size of this error - I do not reject $H_0$ - this means that I claim that due to the obtained data(selection) $H_0$ cannot be refuted - this decision is with error $H_0$(error II This type is not directly controllable and depends on the type of test used. How hypothesis tests are related to interval estimates and how the level of significance enters them will be shown in the next section.\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interval estimation and significance level\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = readxl::read_excel(\"data/uvod.xlsx\")\n", "head(data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["options(repr.plot.width = 12) # width of graphs in Jupyter\n", "par(mfrow = c(1, 2))          # graph matrix 1x2\n", "\n", "boxplot(data$data)\n", "hist(data$data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["moments::skewness(data$data)       # oblique\n", "moments::kurtosis(data$data) - 3   # sharpness\n", "\n", "shapiro.test(data$data)$p.value    # normality test\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(data$data)\n", "mean(data$data)\n", "sd(data$data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We make a 95% interval estimate of the mean using a t-test:\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t.test(data$data, alternative = \"two.sided\", conf.level = 0.95)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now imagine that we want to test the hypothesis:<br>$H_0$: $\\mu = 100$<br>$H_A$: $\\mu \\neq 100$<br>What would be the decision with respect to the calculated IO and so the significance level $\\alpha = 0.05$?\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's further imagine that we want to test the hypothesis:<br>$H_0$: $\\mu = 105$<br>$H_A$: $\\mu \\neq 105$<br>What would be the decision with respect to the calculated IO and so the significance level $\\alpha = 0.05$?\n \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["** What we just did is called the classic test. **<br>We'll show you the classic tests for one-sided alternatives.<br>$H_0$: $\\mu = 105$<br>$H_A$: $\\mu > 105$<br>\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t.test(data$data, alternative = \"greater\", conf.level = 0.95)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["$H_0$: $\\mu = 105$<br>$H_A$: $\\mu < 105$<br>\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t.test(data$data, alternative = \"less\", conf.level = 0.95)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that the first of these one-sided alternatives led to a \"rejection\" of $H_0$. This is because of the comparison of the unlikely $H_0$ with the even less likely $H_A$.\n \n", "#### Net significance test and connection with IC\n \n", "An alternative to the classical test(where we create IO - in the terminology of classical tests the so-called field of admission and its addition to the R critical field) is the so-called pure significance test:\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=105\n", "# H_A: mu<>105\n", "t.test(data$data, mu = 105, alternative = \"two.sided\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["t.test(data$data, mu = 105, alternative = \"two.sided\")$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The net significance test results in a p-value. Based on it, we decide whether or not to reject $H_0$.<br>p-value can be understood as the highest possible level of record, such that our decision is - I do not reject. Thus, the IO / field of acceptance would contain the examined value:\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=105\n", "# H_A: mu<>105\n", "\n", "p.hod = t.test(data$data, mu = 105, alternative = \"two.sided\")$p.value\n", "p.hod\n", "\n", "t.test(data$data, alternative = \"two.sided\", conf.level = 1 - p.hod)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=105\n", "# H_A: mu>105\n", "\n", "p.hod = t.test(data$data, mu = 105, alternative = \"greater\")$p.value\n", "p.hod\n", "\n", "t.test(data$data, alternative = \"greater\", conf.level = 1 - p.hod)$conf.int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=105\n", "# H_A: mu<105\n", "\n", "p.hod = t.test(data$data, mu = 105, alternative = \"less\")$p.value\n", "p.hod\n", "\n", "t.test(data$data, alternative = \"less\", conf.level = 1 - p.hod)$conf.int"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Test overview\n \n", "### Position measures\n \n", "By position measures we mean the data that determines the position of the data, no matter how scattered. For data from the normal distribution we can estimate the mean value, for others the median.\n \n", "#### a) student's t-test\n \n", "- we test the mean value - the data must come from a normal distribution - exploratory: skewness and sharpness lie in(-2,2) - exploratory: QQ graph has points approximately on the line - exactly: using a statistical test, eg Shapiro-Wilk test(shapiro.test(data))\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=100\n", "# H_A: mu<>100\n", "t.test(data$data, mu = 100, alternative = 'two.sided')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=100\n", "# H_A: mu>100\n", "t.test(data$data, mu = 100, alternative = 'greater')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: mu=100\n", "# H_A: mu<100\n", "t.test(data$data, mu = 100, alternative = 'less')$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### b) Wilcoxn test\n \n", "- we test the median - the data must come from a symmetric distribution - exploratory: the skewn lies in(-2,2) - exploratory: the histogram looks approximately symmetrical - exact: using a statistical test, eg the \"lawstat\" package, the \"symmetry.test function\"(data, boot=FALSE) \"\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5<>100\n", "wilcox.test(data$data, mu = 100, alternative = 'two.sided')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5>100\n", "wilcox.test(data$data, mu = 100, alternative = 'greater')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5<100\n", "wilcox.test(data$data, mu = 100, alternative = 'less')$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### c) sign test test\n \n", "- we test the median - select a larger range(>10) - requires the \"BSDA\" library - as the most robust test, it can also be used for discontinuous data - eg order in a list\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5<>100\n", "BSDA::SIGN.test(data$data, md = 100, alternative = 'two.sided')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5>100\n", "BSDA::SIGN.test(data$data, md = 100, alternative = 'greater')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: X_0.5=100\n", "# H_A: X_0.5<100\n", "BSDA::SIGN.test(data$data, md = 100, alternative = 'less')$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Variability measures\n \n", "By measures of variability we mean the data determining the scatter / variability of the data, regardless of the total values. For data from the normal distribution, we can estimate the standard deviation.\n \n", "#### standard deviation test\n \n", "- we test the standard deviation - the data must come from a normal distribution - exploratory: skewness and sharpness lie in(-2,2) - exploratory: QQ graph has points approximately on the line - exactly: using a statistical test, eg Shapiro-Wilk test(shapiro.test(data)) - requires package \"EnvStats\" - function in Rku, compares variance !!!\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: sigma=10\n", "# H_A: sigma<>10\n", "EnvStats::varTest(data$data, sigma.squared = 10*10, \n", "                  alternative = 'two.sided')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: sigma=10\n", "# H_A: sigma>10\n", "EnvStats::varTest(data$data, sigma.squared = 10*10, \n", "                  alternative = 'greater')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: sigma=10\n", "# H_A: sigma<10\n", "EnvStats::varTest(data$data, sigma.squared = 10*10, \n", "                  alternative = 'less')$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Probability of occurrence with one selection\n \n", "#### IO probability\n \n", "- we test the probability - we require a sufficient number of data: $n>\\frac{9}{p(1-p)}$ - Clopper - Pearson's estimate(binom.test) - does not take data as a parameter, but the number of successes and the number of observations\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pi = 0.3\n", "data_bin = runif(n = 100, min = 0, max = 1) < pi\n", "\n", "n = length(data_bin)\n", "x = sum(data_bin)\n", "n\n", "x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: pi=0.2\n", "# H_A: pi<>0.2\n", "binom.test(x = x, n = n, p = 0.2, alternative = 'two.sided')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: pi=0.2\n", "# H_A: pi>0.2\n", "binom.test(x = x, n = n, p = 0.2, alternative = 'greater')$p.value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H_0: pi=0.2\n", "# H_A: pi<0.2\n", "binom.test(x = x, n = n, p = 0.2, alternative = 'less')$p.value"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Examples\n \n", "## Example 1.\n \n", "We have a selection of 216 patients and we measured their protein serum(file testy_jednovyberove.xlsx list bilk_serum). Verify that the average protein serum(Albumin) of all patients of this type(population average \u00b5) differs statistically significantly from 35 g / l.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Read data from xlsx file(using readxl package)\n", "albumin = readxl::read_excel(\"data/testy_jednovyberove.xlsx\",\n", "                             sheet = \"bilk_serum\")\n", "head(albumin)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["colnames(albumin)=\"hodnoty\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Exploratory analysis\n", "boxplot(albumin$hodnoty)\n", "summary(albumin$hodnoty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(albumin$hodnoty) # sd is rounded to 3 valid digits\n", "sd(albumin$hodnoty)     # sd and position rates are rounded to the nearest thousandth\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["** Position test **\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of normality - exploratory\n", "moments::skewness(albumin$hodnoty)    # oblique\n", "moments::kurtosis(albumin$hodnoty)-3  # sharpness\n", "\n", "options(repr.plot.width = 12) # width of graphs in Jupyter\n", "par(mfrow = c(1, 2))          # graph matrix 1x2\n", "\n", "qqnorm(albumin$hodnoty)\n", "qqline(albumin$hodnoty)\n", "hist(albumin$hodnoty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We will use the normality test for the final decision on data normality.\n", "\n", "# The presumption of normality is verified by the Shapirov-Wilkov test.\n", "# H0: Data is a selection from a normal distribution.\n", "# Ha: Data is not a selection from the normal distribution.\n", "shapiro.test(albumin$hodnoty)\n", "# p-value>0.05 ->Na hl. significance of 0.05, the assumption of normality cannot be rejected.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normal OK ->t.test\n", "\n", "# H0: mu=35 g / l\n", "# Ha: mu<>35 g / l\n", "\n", "t.test(albumin$hodnoty, mu=35, alternative = \"two.sided\")\n", "\n", "# p-value<0.05 ->Na hl. significance of 0.05 we reject the null hypothesis\n", "# in favor of the alternative hypothesis\n", "# The mean albumin value differs statistically significantly from 35 g / l.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 2.\n \n", "Survival times for 100 lung cancer patients treated with the new drug are listed in the test_jednovyberove.xlsx list previti file. It is known from previous studies that the average survival of such patients without the administration of a new drug is 22.2 months. Can these data suggest that the new drug prolongs survival?\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Reading data from an xlsx file(using the readxl package)\n", "preziti = readxl::read_excel(\"data/testy_jednovyberove.xlsx\",\n", "                             sheet = \"preziti\")   \n", "head(preziti)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["colnames(preziti)=\"hodnoty\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Exploratory analysis\n", "par(mfrow = c(1, 2))          # matrix of 1x2 graphs\n", "\n", "boxplot(preziti$hodnoty)\n", "hist(preziti$hodnoty)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["** Data contains OP ->we can delete it. Or note that this is probably an exponential distribution and the OPs are not actually there(the division simply behaves this way.) **\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Data contains remote observations. We can list them with the help of f-ce boxplot.\n", "pom=boxplot(preziti$hodnoty, plot = FALSE)\n", "pom$out\n", "# if we decided to remove outliers, then\n", "preziti$hodnoty.bez=preziti$hodnoty # We recommend that you do not overwrite the original data\n", "preziti$hodnoty.bez[preziti$hodnoty %in% pom$out]=NA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Exploratory analysis for data without remote observations\n", "boxplot(preziti$hodnoty.bez)\n", "summary(preziti$hodnoty.bez,na.rm=TRUE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(na.omit(preziti$hodnoty.bez))   # sd is rounded to 3 valid digits\n", "sd(preziti$hodnoty.bez,na.rm=TRUE)     # sd and position measures round. to tenths\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["** Position measure(mean / median) test **\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of normality - exploratory\n", "moments::skewness(preziti$hodnoty.bez,na.rm=TRUE)\n", "moments::kurtosis(preziti$hodnoty.bez,na.rm=TRUE)-3\n", "\n", "par(mfrow = c(1, 2))          # graph matrix 1x2\n", "\n", "qqnorm(preziti$hodnoty.bez)\n", "qqline(preziti$hodnoty.bez)\n", "hist(preziti$hodnoty.bez)\n", "\n", "# QQ - graph and history show that the choice of truth. is not a choice of standards. distribution.\n", "# Both skew and sharpness comply with standards. distribution.\n", "# we will use the normality test.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We verify the assumption of normality by the Shapirs. Wilkov's test.\n", "shapiro.test(preziti$hodnoty.bez)\n", "# p-value<0.05 ->Na hl. significance 0.05, we reject the assumption of normality\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# exploratory assessment of symmetry - historical height and skewness\n", "\n", "# Assumption of symmetry - verification by test\n", "# H0: data comes from symmetric distribution\n", "# HA:~H0\n", "\n", "lawstat::symmetry.test(preziti$hodnoty.bez,boot=FALSE)\n", "# p-value<0.05 ->Na hl. significance 0.05 we reject the assumption of symmetry\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normality rejected ->symmetry rejected ->Sign. test\n", "# H0: median=22.2 months\n", "# Ha: median>22.2 months\n", "\n", "BSDA::SIGN.test(preziti$hodnoty.bez, md=22.2,\n", "                alternative=\"greater\", conf.level=0.95)\n", "\n", "# p-value>0.05 ->Na hl. significance of 0.05, the null hypothesis cannot be rejected\n", "# Median survival time is not statistically significantly greater than 22.2 months.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["median(preziti$hodnoty.bez, na.rm = TRUE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# H0: median=22.2 months\n", "# Ha: median<22.2 months\n", "\n", "BSDA::SIGN.test(preziti$hodnoty.bez, md=22.2,\n", "                alternative=\"less\", conf.level=0.95)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 3.\n \n", "The machine produces piston rings of a given diameter. The manufacturer states that the standard deviation of the ring diameter is 0.05 mm. To verify this information, 80 rings were randomly selected and a standard deviation of 0.04 mm in diameter was calculated. Can this difference be considered statistically significant in terms of improving the quality of production? Verify with a clean significance test. Assume that the diameter of the piston rings has a normal distribution.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Standard deviation test\n", "\n", "# We assume data normality(according to assignment)\n", "n = 80   # file range\n", "s = 0.04 # mm .... sample standard deviation(point estimate of standard deviation)\n", "\n", "# H0: sigma=0.05 mm\n", "# Ha: sigma<0.05 mm\n", "\n", "x.obs = (n-1)*s^2/0.05^2\n", "x.obs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p.hodnota = pchisq(x.obs,n-1)\n", "p.hodnota\n", "\n", "# p.value<0.05 ->At the significance level of 0.05 we reject the null hypothesis\n", "# in favor of an alternative hypothesis\n", "# Direction. the ring diameter deviation is statistically significantly less than 0.05 mm.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 4.\n \n", "The machine produces piston rings of a given diameter. The manufacturer states that the standard deviation of the ring diameter is 0.05 mm. To verify this information, 80 rings were randomly selected and their diameter was measured(file testy_jednovyberove.xlsx list krouzky). Can the results obtained be considered statistically significant in terms of improving the quality of production? Verify with a clean significance test.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Reading data from xlsx file(using readxl package)\n", "krouzky = readxl::read_excel(\"data/testy_jednovyberove.xlsx\",\n", "                             sheet = \"krouzky\")  \n", "head(krouzky)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["colnames(krouzky)=\"hodnoty\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Exploratory analysis\n", "boxplot(krouzky$hodnoty)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Data contains remote observations. We can list them with the help of f-ce boxplot.\n", "pom = boxplot(krouzky$hodnoty, plot = FALSE)\n", "pom$out\n", "# if we decided to remove outliers, then\n", "krouzky$hodnoty.bez = krouzky$hodnoty\n", "krouzky$hodnoty.bez[krouzky$hodnoty %in% pom$out] = NA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Exploratory analysis for data without remote observations\n", "summary(krouzky$hodnoty.bez,na.rm=TRUE)\n", "boxplot(krouzky$hodnoty.bez)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["length(na.omit(krouzky$hodnoty.bez))# sd is rounded to 3 valid digits\n", "sd(krouzky$hodnoty.bez,na.rm=TRUE)  # sd and position measures round. per thousandths\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of normality - exploratory\n", "moments::skewness(krouzky$hodnoty.bez,na.rm=TRUE)\n", "moments::kurtosis(krouzky$hodnoty.bez,na.rm=TRUE)-3\n", "\n", "par(mfrow = c(1, 2))          # graph matrix 1x2\n", "\n", "qqnorm(krouzky$hodnoty.bez)\n", "qqline(krouzky$hodnoty.bez)\n", "hist(krouzky$hodnoty.bez)\n", "# Both skew and sharpness comply with standards. distribution.\n", "# We will use for the final decision on data normality\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# normality test.\n", "# We verify the assumption of normality by the Shapirs. Wilkov's test.\n", "shapiro.test(krouzky$hodnoty.bez)\n", "# p-value>0.05 ->Na hl. significance of 0.05 cannot be assumed norms. reject\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# variability test ->variance test\n", "\n", "# H0: sigma=0.05 mm\n", "# Ha: sigma<0.05 mm\n", "EnvStats::varTest(krouzky$hodnoty.bez, sigma.squared = 0.05^2,\n", "                  alternative = \"less\")\n", "\n", "# p-value<0.05 ->At the significance level of 0.05, we reject H0 in favor of Ha\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# How to find a 95% interval estimate of the standard deviation?\n", "pom = EnvStats::varTest(krouzky$hodnoty.bez,sigma.squared = 0.05^2,\n", "                        alternative = \"less\", conf.level=0.95)\n", "\n", "sqrt(pom$conf.int)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Example 5.\n \n", "TT states that 1% of their resistors do not meet the required criteria. 15 unsuitable resistors were found in the tested delivery of 1000 pieces. Does this result confirm TT's assertion? Verify with a clean significance test.\n \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 1000   # selection range\n", "x = 15     # number of \"successes\"\n", "p = x/n    # relative frequency(probability point estimate)\n", "p "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Verification of assumptions\n", "9/(p*(1-p))\n", "# We further assume n / N<0.05, ie that the given population(resistors) has a range\n", "# at least 1000 / 0.05=1000 * 20=20,000 resistors\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Clopper - Pearson(exact) test\n", "# # H0: pi=0.01\n", "# # Ha: pi<>0.01\n", "\n", "binom.test(x = x, n= n, p = 0.01, alternative=\"two.sided\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# # Clopper - Pearson(exact) test\n", "# # H0: pi=0.01\n", "# # Ha: pi>0.01\n", "\n", "binom.test(x = x, n= n, p = 0.01, alternative=\"greater\")\n", "\n", "# At the significance level of 0.05 we do not reject H0\n", "# The share of defective resistors in production cannot be expected to be statistically significant\n", "# exceeds 1%.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.0.5"}}, "nbformat": 4, "nbformat_minor": 4}